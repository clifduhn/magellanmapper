# Stats for Clrbrain
# Author: David Young, 2018
"""Stats calculations and text output for Clrbrain.

Attributes:
"""

import copy
import csv
from collections import OrderedDict
import numpy as np
import pandas as pd
from scipy import stats

from clrbrain import config

def _volumes_mean_err(group_dict, key_mean, key_sem, vals, mask, ci=None):
    """Calculate the mean and error values, storing them in the given group 
    dictionary.
    
    Values are filtered by ``mask``, and empty (ie near-zero or None) volumes 
    are excluded as well. By default, SEM is used as the error measurement. 
    If a confidence interval argument is given, the size of the CI will be 
    used instead of SEM.
    
    Args:
        group_dict: Dictionary where the SEM will be stored.
        key_mean: Key at which the mean will be stored.
        key_sem: Key at which the SEM will be stored.
        vals: Values from which to calculate.
        mask: Boolean array corresponding to ``vals`` of values to keep.
        ci: Confidence interval alpha level; if None, CI will not be calculated.
    """
    # convert to Numpy array to filter by make
    vals = np.array(vals)
    if mask is not None:
        vals = vals[mask]
    print("group vals raw: {}, mask: {}, n: {}".format(vals, mask, vals.size))
    
    # further prune to remove None or near-zero values (ie no volume found)
    vals = vals[vals != None] # TODO: check if actually encounter None vals
    vals = vals[vals > config.POS_THRESH]
    mean = np.mean(vals)
    sem = stats.sem(vals)
    err = sem
    if ci:
        # use confidence interval instead of SEM if CI percentage given
        confidence = stats.t.interval(ci, len(vals) - 1, loc=mean, scale=sem)
        err = confidence[1] - mean
        '''
        # alternative method, which appears to give same result
        confidence = stats.t.ppf((1 + ci)/2., len(vals) - 1)
        err = sem * confidence
        '''
    print("mean: {}, err: {}, n after pruning: {}".format(mean, err, vals.size))
    group_dict[key_mean].append(mean)
    group_dict[key_sem].append(err)

def volume_stats(volumes_dict, densities, groups=[""], unit_factor=1.0, 
                 ci=0.95):
    """Generate stats for volumes and densities by region and groups.
    
    Args:
        volumes_dict: Dictionary of volumes as generated by 
            :func:``register.volumes_by_id`` or 
            :func:``register.group_volumes``, including values from 
            individual or grouped experiments, respectively.
        densities: True if densities should be extracted and displayed from 
            the volumes dictionary; defaults to False.
        groups: List of groupings for each experiment. List length should be 
            equal to the number of values stored in each label's list in 
            ``volumes_dict``. Defaults to a list with an empty string, in 
            which case each label's value will be assumed to be a scalar 
            rather than a list of values.
        unit_factor: Factor by which volumes will be divided to adjust units; 
            defaults to 1.0.
        ci: Confidence intervale alpha level, which can be None to ignore.
    
    Returns:
        Tuple of ``group_dict``, ``names``, ``mean_keys``, ``err_keys``, and 
        ``measurement_keys``, ``measurement_units``.
        ``group_dict`` is a dictionary with group names as keys. Each value is 
        another dictionary with ``meausurement_keys`` as keys, such as 
        "volumes" or "densities", and the corresponding ``measurement_units``, 
        such as "cubic mm". Values are in turn additional dictionaries 
        with ``mean_keys`` as keys for sub-groups  such as "right" or "left" 
        that could be means or simple counts,
        and ``err_keys`` as keys for error values, such "SEM_of_the_right" 
        or "SEM_of_the_left". These values are 2-dimensional lists in the 
        format, 
        ``[[name0_val0, name0_val2, ...], [name1_val0, name2_val1, ...], ...]``,
        where ``names`` correspond to these values. If only one sub-list is 
        given, such as for individual experiments rather than a group of 
        experiments, error values are assumed to be None or empty lists.
    """
    # "side" and "mirrored" for opposite side (R/L agnostic)
    SIDE = "side"
    MIR = "mirrored"
    SIDE_ERR = SIDE + "_err"
    MIR_ERR = MIR + "_err"
    VOL = "volume"
    BLOBS = "nuclei"
    DENS = "density"
    multiple = groups is not None
    groups_unique = np.unique(groups)
    groups_dict = {}
    for group in groups_unique:
        print("Finding volumes and densities for group {}".format(group))
        # dictionary of mean and SEM arrays for each side, which will be 
        # populated in same order as experiments in volumes_dict
        vol_group = {SIDE: [], MIR: [], SIDE_ERR: [], MIR_ERR: []}
        blobs_group = copy.deepcopy(vol_group)
        dens_group = copy.deepcopy(vol_group)
        groups_dict[group] = {
            VOL: vol_group, BLOBS: blobs_group, DENS: dens_group}
        group_mask = np.array(groups) == group if multiple else None
        for key in volumes_dict.keys():
            # find negative keys based on the given positive key to show them
            # side-by-side
            if key >= 0:
                # get volumes in the given unit, which are scalar for 
                # individual image, list if multiple images
                vol_side = np.divide(
                    volumes_dict[key][config.VOL_KEY], unit_factor)
                vol_mirrored = np.divide(
                    volumes_dict[-1 * key][config.VOL_KEY], unit_factor)
                # store vol and SEMs in vol_group
                if isinstance(vol_side, np.ndarray):
                    # for multiple experiments, store mean and error
                    _volumes_mean_err(
                        vol_group, SIDE, SIDE_ERR, vol_side, group_mask, ci=ci)
                    _volumes_mean_err(
                        vol_group, MIR, MIR_ERR, vol_mirrored, group_mask, 
                        ci=ci)
                else:
                    # for single experiment, store only vol
                    vol_group[SIDE].append(vol_side)
                    vol_group[MIR].append(vol_mirrored)
                
                if densities:
                    # calculate densities based on blobs counts and volumes
                    blobs_side = volumes_dict[key][config.BLOBS_KEY]
                    blobs_mirrored = volumes_dict[-1 * key][config.BLOBS_KEY]
                    print("id {}: blobs R {}, L {}".format(
                        key, blobs_side, blobs_mirrored))
                    density_side = np.nan_to_num(
                        np.divide(blobs_side, vol_side))
                    density_mirrored = np.nan_to_num(
                        np.divide(blobs_mirrored, vol_mirrored))
                    if isinstance(density_side, np.ndarray):
                        # density means and SEMs, storing the SEMs
                        _volumes_mean_err(
                            blobs_group, SIDE, SIDE_ERR, blobs_side, 
                            group_mask, ci=ci)
                        _volumes_mean_err(
                            blobs_group, MIR, MIR_ERR, blobs_mirrored, 
                            group_mask, ci=ci)
                        _volumes_mean_err(
                            dens_group, SIDE, SIDE_ERR, density_side, 
                            group_mask, ci=ci)
                        _volumes_mean_err(
                            dens_group, MIR, MIR_ERR, density_mirrored, 
                            group_mask, ci=ci)
                    else:
                        blobs_group[SIDE].append(blobs_side)
                        blobs_group[MIR].append(blobs_mirrored)
                        dens_group[SIDE].append(density_side)
                        dens_group[MIR].append(density_mirrored)
    names = [volumes_dict[key][config.ABA_NAME] 
             for key in volumes_dict.keys() if key >= 0]
    return groups_dict, names, (MIR, SIDE), (MIR_ERR, SIDE_ERR), \
           (VOL, BLOBS, DENS), \
           ("cubic \u00b5m", "nuclei", "nuclei / cubic \u00b5m")

def volume_stats_to_csv(vol_stats, path, groups=[""]):
    """Export volume mean stats to CSV file.
    
    Args:
        vol_stats: Dictionary of volume mean/error stats as given by 
            :func:``volume_stats``.
        path: Path to output CSV file. If the filename does not end with .csv, 
            this extension will be appended.
        groups: List of groups; defaults to a list with an empty string, which 
            is the default for ``vol_stats`` with no group, including an 
            individual sample.
    """
    # unpack volume stats
    groups_dict, names, means_keys, sem_keys, meas_keys, meas_units = vol_stats
    ext = ".csv"
    if not path.endswith(ext): path += ext
    
    # build lists of all values for the given measurements, with an element 
    # for each group-subgroup combo 
    # (eg [WT_R_vols, WT_L_vols, het_R_vols, het_L_vols])
    vols = []
    blobs = []
    dens = []
    errs_vols = []
    errs_blobs = []
    errs_dens = []
    bar_colors = []
    header = ["Region"]
    groups_unique = np.unique(groups)
    for group_name in groups_unique:
        group = groups_dict[group_name]
        for means_key in means_keys:
            vols.append(group[meas_keys[0]][means_key])
            blobs.append(group[meas_keys[1]][means_key])
            dens.append(group[meas_keys[2]][means_key])
        for sem_key in sem_keys:
            errs_vols.append(group[meas_keys[0]][sem_key])
            errs_blobs.append(group[meas_keys[1]][sem_key])
            errs_dens.append(group[meas_keys[2]][sem_key])
        # add a set of headers for each group
        header.extend("{0}_vol_L,{0}_vol_sem_L,{0}_blobs_L,{0}_vol_blobs_L,"
                      "{0}_density_L,{0}_density_sem_L,"
                      "{0}_vol_R,{0}_vol_sem_R,{0}_blobs_R,"
                      "{0}_blobs_sem_R,{0}_density_R,{0}_density_sem_R"
                      .format(group_name).split(","))
    
    with open(path, "w", newline="") as csv_file:
        stats_writer = csv.writer(csv_file, delimiter=",")
        stats_writer.writerow(header)
        
        # output row for each name, where names list matches each vol list 
        # (i) within vols, and each vol list is for a separate group (j)
        for i in range(len(names)):
            row = [names[i]]
            for j in range(len(vols)):
                vol = vols[j][i]
                err_vol = None
                if errs_vols[j] and len(errs_vols[j]) > 0:
                    err_vol = errs_vols[j][i]
                blob = blobs[j][i]
                err_blobs = None
                if errs_blobs[j] and len(errs_blobs[j]) > 0:
                    err_blobs = errs_blobs[j][i]
                den = dens[j][i]
                err_den = None
                if errs_dens[j] and len(errs_dens[j]) > 0:
                    err_den = errs_dens[j][i]
                row.extend([str(vol), str(err_vol), str(blob), str(err_blobs), 
                            str(den), str(err_den)])
            print(row)
            stats_writer.writerow(row)

def volumes_to_csv(volumes_dict, path, groups=[""], unit_factor=1.0):
    """Export volumes from each sample to Pandas format and CSV file.
    
    Args:
        volumes_dict: Dictionary of volumes as generated by 
            :func:``register.volumes_by_id`` or 
            :func:``register.group_volumes``, including values from 
            individual or grouped experiments, respectively.
        path: Path to output CSV file. If the filename does not end with .csv, 
            this extension will be appended.
        groups: List of groupings for each experiment. List length should be 
            equal to the number of values stored in each label's list in 
            ``volumes_dict``. Defaults to a list with an empty string, in 
            which case each label's value will be assumed to be a scalar 
            rather than a list of values.
        unit_factor: Factor by which volumes will be divided to adjust units; 
            defaults to 1.0.
    
    Returns:
        Pandas ``DataFrame`` with volume and density as separate columns for 
        each region, with one line per sample per side. Eg: 
        ```
        Sample, Geno, Side, Vol_01, Dens_01, Vol_02, Dens_02, ...
        0, 0, L, 1.1, 0.3, 1.2, 0.2, ...
        0, 0, R, 0.9, 0.2, 1.1, 0.2, ...
        1, 0, L, 1.0, 0.3, 1.1, 0.3, ...
        ```
    """
    header = ["Sample", "Geno", "Side"]
    num_samples = len(groups)
    samples = list(range(num_samples)) * 2
    genos = groups * 2
    sides = ["L"] * num_samples
    sides.extend(["R"] * num_samples)
    vol_dens = []
    for key in volumes_dict.keys():
        # find negative keys based on the given positive key to group them
        if key >= 0:
            header.append("Vol_{}".format(key))
            header.append("Dens_{}".format(key))
            # get volumes in the given unit, which are scalar for 
            # individual image, list if multiple images
            vol_side = np.divide(
                volumes_dict[key][config.VOL_KEY], unit_factor)
            vol_mirrored = np.divide(
                volumes_dict[-1 * key][config.VOL_KEY], unit_factor)
            # calculate densities based on blobs counts and volumes
            blobs_side = volumes_dict[key][config.BLOBS_KEY]
            blobs_mirrored = volumes_dict[-1 * key][config.BLOBS_KEY]
            density_side = np.nan_to_num(np.divide(blobs_side, vol_side))
            density_mirrored = np.nan_to_num(
                np.divide(blobs_mirrored, vol_mirrored))
            
            # concatenate vol/dens from each side into 1d list and interleave 
            # in master list
            vols = vol_side.tolist()
            vols.extend(vol_mirrored.tolist())
            vol_dens.append(vols)
            density = density_side.tolist()
            density.extend(density_mirrored.tolist())
            vol_dens.append(density)
    
    # pool lists and add to Pandas data frame
    volumes_dataset = list(zip(samples, genos, sides, *vol_dens))
    data_frame = pd.DataFrame(data=volumes_dataset, columns=header)
    ext = ".csv"
    if not path.endswith(ext): path += ext
    data_frame.to_csv(path, index=False)
    print("exported volume data per sample to CSV at {}".format(path))
    return data_frame

def regions_to_pandas(volumes_dict, level, groups=[""], unit_factor=1.0):
    """Export volumes from each sample to Pandas format and CSV file, with 
    measurements for each region on a separate line.
    
    Args:
        volumes_dict: Dictionary of volumes as generated by 
            :func:``register.volumes_by_id`` or 
            :func:``register.group_volumes``, including values from 
            individual or grouped experiments, respectively.
        level: Ontology level at which to show volumes and densities.
        path: Path to output CSV file. If the filename does not end with .csv, 
            this extension will be appended.
        groups: List of groupings for each experiment. List length should be 
            equal to the number of values stored in each label's list in 
            ``volumes_dict``. Defaults to a list with an empty string, in 
            which case each label's value will be assumed to be a scalar 
            rather than a list of values.
        unit_factor: Factor by which volumes will be divided to adjust units; 
            defaults to 1.0.
    
    Returns:
        Pandas ``DataFrame`` with regional measurements given as one region 
        per line.
    """
    header = [
        "Sample", "Geno", "Side", "Region", "Level", "Vol", "Dens", "Nuclei"]
    num_samples = len(groups)
    #data = {k: [] for k in header} # retains order for Python 3.6 but not <
    data = OrderedDict()
    for h in header:
        data[h] = []
    for key in volumes_dict.keys():
        # find negative keys based on the given positive key to group them
        if key >= 0:
            # get volumes in the given unit, which are scalar for 
            # individual image, list if multiple images
            vol_side = np.divide(
                volumes_dict[key][config.VOL_KEY], unit_factor)
            vol_mirrored = np.divide(
                volumes_dict[-1 * key][config.VOL_KEY], unit_factor)
            # calculate densities based on blobs counts and volumes
            blobs_side = volumes_dict[key][config.BLOBS_KEY]
            blobs_mirrored = volumes_dict[-1 * key][config.BLOBS_KEY]
            density_side = np.nan_to_num(np.divide(blobs_side, vol_side))
            density_mirrored = np.nan_to_num(
                np.divide(blobs_mirrored, vol_mirrored))
            
            # concatenate vol/dens from each side into 1d list
            data[header[0]].extend(list(range(num_samples)) * 2)
            data[header[1]].extend(groups * 2)
            data[header[2]].extend(["L"] * num_samples)
            data[header[2]].extend(["R"] * num_samples)
            data[header[3]].extend([key] * num_samples * 2)
            data[header[4]].extend([level] * num_samples * 2)
            data[header[5]].extend(vol_side.tolist())
            data[header[5]].extend(vol_mirrored.tolist())
            data[header[6]].extend(density_side.tolist())
            data[header[6]].extend(density_mirrored.tolist())
            data[header[7]].extend(blobs_side)
            data[header[7]].extend(blobs_mirrored)
            
    # pool lists and add to Pandas data frame
    data_frame = pd.DataFrame(data=data, columns=header)
    return data_frame

def data_frames_to_csv(data_frames, path):
    ext = ".csv"
    if not path.endswith(ext): path += ext
    combined = pd.concat(data_frames)
    combined.to_csv(path, index=False)
    print("exported volume data per sample to CSV at {}".format(path))

if __name__ == "__main__":
    print("Starting Clrbrain stats...")
